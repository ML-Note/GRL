

<font color=LightCoral>**Problem:**</font>

<font color=LightBlue >**Solution:**</font>

<font color=Lime  >**Definition:**</font>

<font color=LightSalmon >**Remarks:**</font>

<font color=Aqua >**Lemma Theorem**</font>

<font color=Red >**Note:**</font>

<font color=DarkViolet >**Assumption:**</font>

<font color=HotPink >***Proof:***</font>

---

<center> <font size=6 ><b>8.9.Generative Graph Models</b></font></center> 

---

| backdrop  |    背景    |  crafting   |  制作  |    downside    |  缺点  |
| :-------: | :--------: | :---------: | :----: | :------------: | :----: |
|   motif   |    主题    | interrogate |  审问  |      lieu      |  代替  |
|   lieu    | 代替、场所 |   nascent   | 新生的 |     eschew     |  回避  |
|  blurry   |   模糊的   |  snapshot   |  快照  |    pivotal     | 关键的 |
|  nascent  |   新生的   | stagnation  |  停滞  | solidification |  凝固  |
| ingrained | 根深蒂固的 |             |        |                |        |
|           |            |             |        |                |        |
|           |            |             |        |                |        |
|           |            |             |        |                |        |
|           |            |             |        |                |        |
|           |            |             |        |                |        |



# 8. Traditional Graph Generation Approaches

之前的章节都是介绍学习图表示的方法。这里讨论一个不同但又非常相关的工作：**Graph Generation**

图生成的目标是建立能够生成真实的图结构的模型。希望输出是一个图$\mathcal{G}$。图生成的挑战是生成具有确定特征(certain desirable properties)的图。接下来我们可以看到"desirable properties"的定义以及我们如何执行图形生成。



## 8.1 Overview of Traditional Approaches

传统的图生成通常包含几个确定的生成过程(generative process)，它们定义了边是如何创造的。

在大多数情况下，我们可以将此生成过程作为一种指定存在于两个节点$u$和$v$之间的边的概率或可能性$P(\pmb{A}[u,v]=1)$的方法。

挑战在于设计某种生成过程，这种生成过程既易于处理(tractable)，又能够生成具有非平凡属性(non-trivial properties)或特征(characteristics)的图。可处理性非常重要，因为我们希望能够对生成的图形进行采样或分析。然而，我们也希望这些图具有一些特性，使它们成为我们在现实世界中看到的各种图的良好模型。

本小节回顾了三个小且具有代表性的传统图生成方法。Newman（P104）对更多的方法有介绍



## 8.2 $\pmb{Erd \ddot{o}s-R\acute{e}nyi}$ model

$\pmb{Erd \ddot{o}s-R\acute{e}nyi}$ (ER) model(P104)，在这个模型中，我们将在任何一对节点之间发生一条边的可能性定义为
$$
P(\pmb{A}[u,v] =1) = r ,\forall u,v \in \mathcal{V},u \neq v
$$
其中$r \in [0,1]$是控制图的密度的参数。

这个模型因为它的简单很受欢迎。为了生成一个随机的ER图，我们只需选择（或采样）我们想要多少节点，设置密度参数$r$，然后使用方程（1）来生成邻接矩阵。每个边的概率都是独立的，时间复杂度为$O(|\mathcal{V}|^2)$

很明显这个模型的缺点是产生的并不是实际的图，我们只能控制边的密度



## 8.3 Stochastic Block Models

捕捉ER model所不能捕捉的其他性质，一类流行的方法是：**stochastic block models(SBMs)**。它们寻求生成具有**社区结构**的图形。

基本的SBM模型，有$\gamma$个不同的区：$\mathcal{C}_1,...,\mathcal{C}_\gamma$。每个节点$u \in \mathcal{V}$有概率$p_i$属于第i区。例如$p_i = P(u \in \mathcal{C}_i),\forall u \in \mathcal{V},i=1,...,\gamma$其中$\sum_{i=1}^\gamma p_i =1$。边概率被区对区的概率矩阵$\pmb{C} \in [0,1]^{\gamma \times \gamma}$，其中$\pmb{C}[i,j]$给出了$\mathcal{C}_i$中的节点和$\mathcal{C_j}$中的节点之间发生边的概率。基本SBM模型的生成过程如下：

1. 对于每个节点$u \in \mathcal{V}$，我们通过从$(p_i,...,p_\gamma)$定义的分类分布中抽样，将$u$分配给区$\mathcal{C}_i$

2. 对于每对节点$u \in \mathcal{C}_i$和$v \in \mathcal{C}_j$我们抽样一个边根据
   $$
   P(\pmb{A}[u,v]=1) = \pmb{C}[i,j]
   $$

该算法的创新就是产生边的概率与不同的blocks相关，这允许我们产生拥有社区结构的图。也有许多SBM框架的变种，包括对于bipartite graphs、具有节点特征的图、以及从数据推断SBM参数的方法(P105)



## 8.4 Preferential Attachment

如同ER模型，SBM方法的局限性在于，它不能捕捉到在大多数现实世界的图中存在的单个节点的结构特征。比如SBM模型中同一个区的节点拥有同样的度分布。

**Preferential Attachment(PA)** model尝试去捕捉现实度分布的特征(P105)。PA模型是基于许多真实世界的图显示幂律度(power law)分布的假设而建立的，这意味着一个节点$u$具有$d_u$度的概率大致由以下方程给出：
$$
P(d_u= k)  \propto k^{-\alpha}
$$
其中$\alpha>1$。power law distribution与其他相关分布，都有后尾性质。形式上，重尾意味着极值比指数分布慢于零。在度分布的情况下，这种重尾性质本质上意味着有一个非零的机会遇到少量的非常高的度节点。

PA模型使用一个简单的生成过程生成显示幂律度分布的图：

1. 首先，我们初始化一个具有$m_0$个节点的全连通图。

2. 接下来，我们迭代地将$n-m_0$节点添加到此图中。对于我们在迭代$t$中添加的每个新节点$u$，我们将其连接到图中$m < m_0$的现有节点，并根据以下概率分布通过不放回抽样选择其$m$个邻居：
   $$
   P(\pmb{A}[u,v]) = \frac{d_v^{(t)}}{\sum_{v' \in  \mathcal{V}^{(t)}}d_{v'}^{(t)}}
   $$
   其中$d_v^{(t)}$表示节点$v$在第$t$次迭代的度。$\mathcal{V}^{(t)}$表示在迭代$t$之前已经添加到图中的节点集。

关键思想是PA模型以与现有节点度成正比的概率将新节点与现有节点连接起来。可以证明，上述PA模型使用α=3生成具有幂律度分布的连通图(P106)。

PA模型与ER和SBM模型不同的一个重要方面是，生成过程是自回归的(autoregressive)。

注：关于真实世界数据中实际幂律分布的普遍性，存在大量争议。有令人信服的证据表明，许多假定的幂律分布事实上更适合于对数正态分布。(P106)



## 8.5 Traditional Applications

历史上，这些传统的生成模型曾被用于两个关键的应用程序：

**Generating synthetic data for benchmarking and analysis tasks**

**Creating null models**

一般来说，传统的图形生成模型使我们能够询问哪些什么样的图形特征可以很简单地用简单的生成过程来解释。从统计意义上说，它们为我们提供了零模型null model，我们可以作为理解真实图的参考点。





# 9.Deep Generative Models

然而，这些传统方法的一个关键限制是，它们依赖于一个固定的、手工制作的生成过程。他们缺乏从数据中学习生成模型的能力。

本章所介绍的模型将寻求学习基于一组训练图的图形生成模型。相反，这些方法的目标是设计可以观察一组图$\{\mathcal{G}_1,...,\mathcal{G}_n\}$，并学习生成与这个训练集具有相似特征的图的模型。

我们将介绍一系列基本的图形深度生成模型。这些模型将采用三种最流行的方法来构建通用的深度生成模型：variational autoencoders (VAEs), generative adversarial networks (GANs), and autoregressive models. 这些方法有时也会结合起来：例如VAEs与autoregressive models

另外前两个模型都是 generate an entire graph *all-at-once* 最后一个是 generate a graph *incrementally* 。这些自回归方法与前一章的preferential attachment model相似，即在生成过程中在每一步添加一条边的概率取决于什么边在之前被添加到图中。



## 9.1 Variational Autoencoder Approaches

**Variational autoencoders (VAEs) **(P109)将VAE应用于图背后的关键思想可以总结如下: 我们的目标是训练一个概率解码模型$p_{\theta}(\pmb{A}|\pmb{Z})$，从中我们可以取样真实的图形 (i.e., adjacency matrices) $\pmb{\hat{A}} \sim p_{\theta}(\pmb{A}|\pmb{Z})$通过调节一个潜在的变量$\pmb{Z}$。在概率的意义上，我们的目标是学习邻接矩阵上的条件分布（该分布以某个潜在变量为条件）。

为了训练VAE，我们将概率解码器(probabilistic decoder)与概率编码器模型(probability encoder model)$q_{\theta}(\pmb{Z}|\mathcal{G})$相结合。该编码器模型将输入图$\mathcal{G}$映射到潜在变量$\pmb{Z}$上的后验分布。其思想是，我们联合训练编码器和解码器，以便解码器能够在给定从编码器采样的潜在变量$\pmb{Z} \sim q_{\theta}(\pmb{Z}|\mathcal{G})  $的情况下重建训练图。然后，在训练之后，我们可以丢弃编码器，通过从一些（无条件）先验分布中采样潜在变量$\pmb{Z} \sim p(\pmb{Z})$并将这些采样的潜在变量提供给解码器来生成新的图。

在更正式和数学的细节中，要为图形构建一个VAE，我们必须指定以下关键成分：

1. A *probabilistic encoder* model $q_\phi$，概率编码器模型将$\mathcal{G}$作为输入。从这个输入中，$q_\phi$然后通过潜在表示(latent representations)定义了一个分布$q_{\phi}(\pmb{Z}|\mathcal{G})$。一般来说，在VAEs中，使用高斯随机变量的重参数化技巧(reparameterization trick)来设计一个概率$q_\phi$函数。也就是说，我们指定潜在条件分布为$\pmb{Z} \sim \mathcal{N}(\mu_{\phi}(\mathcal{G}),\sigma(\phi(\mathcal{G})))$，其中$\mu_\phi,\sigma_{\phi}$是生成正态分布的均值和方差参数的神经网络，从中我们采样潜在嵌入$\pmb{Z}$。
2. A *probabilistic decoder* model $p_\theta$，解码器将潜在表示$\pmb{Z}$作为输入，并使用该输入指定图上的条件分布。在本章中，我们假设$p_{\theta}$定义了邻接矩阵项上的条件分布，例如，我们可以计算$p_{\theta}(\pmb{A}[u,v] = 1|\pmb{Z})$
3. A *prior distribution* $p(\pmb{Z})$ over the latent space，在本章中我们采用标准高斯先验分布$\pmb{Z} \sim \mathcal{N}(\pmb{0,1})$，通常VAEs都使用这个

给定这些成分和训练图集合$\{\mathcal{G}_1,...,\mathcal{G}_2\}$，我们可以通过最小化evidence likelihood lower bound（ELBO）来训练VAE模型：
$$
\mathcal{L} = \sum_{\mathcal{G}_i \in \{\mathcal{G}_1,...,\mathcal{G}_2\}} \mathbb{E}_{q_{\theta}(\pmb{Z}|\mathcal{G}_i)} [p_{\theta}(\mathcal{G}_i|\pmb{Z})] - KL(q_{\theta}(\pmb{Z}|\mathcal{G}_i)\| p(\pmb{Z}))
$$
基本的思想是：我们力求最大限度地提高解码器的重建能力，也就是说，似然项：$\mathbb{E}_{q_{\theta}(\pmb{Z}|\mathcal{G}_i)} [p_{\theta}(\mathcal{G}_i|\pmb{Z})]$—同时最小化后验潜分布$q_\theta(\pmb{Z}|\mathcal{G}_i)$和先验$p(\pmb{Z})$的KL散度。

ELBO损失函数背后的动机植根于变分推理理论(variational inference)(P110)。然而，关键的直觉是，我们希望在潜在表示上生成分布，以便满足以下两个（冲突的）目标：

1. 采样的潜在表示编码足够的信息，使我们的解码器能够重建输入。
2. 潜在分布尽可能接近先前的分布。

第二个目标起到正则化器的作用，确保即使我们从先前的$p(\pmb{Z})$中采样潜在表示，我们也可以解码有意义的图。如果我们想在训练后生成新的图，那么第二个目标至关重要：我们可以通过从先前的图中采样并将这些潜在嵌入提供给解码器来生成新的图，并且这个过程只有在满足第二个目标的情况下才会起作用。<font color=Red >**不懂为什么$\pmb{Z}$也要有个分布**</font>

接下来将介绍两种不同的VAE思路



### 9.1.1 Node-Level Latents

我们将研究的第一种方法建立在基于节点嵌入的编码和解码图的思想之上，参考第三章。种方法的关键思想是编码器为图中的每个节点生成潜在表示。然后，解码器将成对嵌入作为输入，并使用这些嵌入来预测两个节点之间出现边缘的可能性。这种方法称为Variational Graph Autoencoder(VGAE) (P111)



**Encoder Model**

encoder model能够基于第五章所讨论的任何GNN结构。给定邻接矩阵$\pmb{A}$和节点特征$\pmb{X}$作为输入，我们使用两个单独的GNN分别生成均值和方差参数，以该输入为条件：
$$
\mu_{\pmb{Z}} = GNN_\mu(\pmb{A},\pmb{X}) \quad \log \sigma_{\pmb{Z}} = GNN_{\sigma}(\pmb{A},\pmb{X})
$$
其中，$\mu_{\pmb{Z}}$是一个$|\mathcal{V} |\times d$-dimensional matrix。它指定输入图中每个节点的平均嵌入值(each node in the input graph)。$\log \sigma_{\pmb{Z}} \in \mathbb{R}^{|\mathcal{V}| \times d}$矩阵同样指定每个节点潜在嵌入的对数方差。

给定编码$\mu_{\pmb{Z}}$和$\log \sigma_{\pmb{Z}}$参数，我们可以通过计算对一组潜在节点嵌入进行采样
$$
\pmb{Z} = \epsilon \circ \exp(\log(\sigma_{\pmb{Z}})) +\mu_{\pmb{Z}}
$$
其中$\epsilon \sim \mathcal{N}(\pmb{0},\pmb{1})$ 是具有独立抽样单位正态项的$|\mathcal{V}| \times d$维矩阵。

注：参数化对数方差通常比直接参数化方差更稳定。



**The Decoder Model**

给定一个采样节点嵌入矩阵$\pmb{Z} \in \mathbb{R}^{|\mathcal{V}| \times d}$，解码器模型的目标是预测图中所有边的可能性。形式上，解码器要确定$p_{\theta}(\pmb{A}|\pmb{Z})$，有许多技术可以使用，比如在第三章讨论的various edge decoders，在原始的VGAE中(P112)使用了 simple dot-product decoder
$$
p_{\theta}(\pmb{A}[u,v]=1|\pmb{z}_u,\pmb{z}_v) = \sigma(\pmb{z}_u^T \pmb{z}_v) 
$$
其中$\sigma$表示sigmoid函数。然而请注意，只要这些解码器生成有效的概率值，就可以使用各种边缘解码器。？？

为了使用这种方法计算方程（5）中的重建损失，我们只需假设边之间的独立性，并定义整个图上的后验$p_{\theta}(\mathcal{G}|\pmb{Z})$，如下所示：
$$
p_{\theta}(\mathcal{G}|\pmb{Z}) = \prod_{(u,v) \in \mathcal{V}^2} p_{\theta}(\pmb{A}[u,v] = 1 | \pmb{z}_u,\pmb{z}_v)
$$
对应于边缘概率上的二元交叉熵损失。为了在训练后生成离散图，我们可以根据方程（8）中的后验贝努利分布对边进行采样。



**Limitations**

在前面几节中描绘的基本VGAE模型定义了一个有效的图形生成模型。在训练该模型以重构一组训练图之后，我们可以从标准正态分布中采样节点嵌入$\pmb{Z}$，并使用我们的解码器生成一个图。主要问题是解码器没有参数，因此如果没有训练图作为输入，模型无法生成非平凡图结构。事实上，一开始VGAE模型作为生成节点嵌入的方法，并不打没有将其作为采样新图形的生成模型。(P112)

一些论文提出通过使解码器更强大来解决VGAE作为生成模型的局限性。例如，Grover等人(P112)建议使用基于GNN的“迭代”解码器来增强解码器。尽管如此，简单的节点级VAE方法尚未成为一种成功且有用的图形生成方法。它在重建任务和作为自动编码器框架方面取得了巨大的成果，但作为一种生成模型，这种简单的方法受到了严重的限制。



### 9.1.2 Graph-level Latents

之前是点级别的方法，接下来是图latent representations。(P113) **GraphVAE**

**Encoder Model**

图级VAE方法中的编码器模型可以是带有池层的任意GNN模型。特别的，我们令GNN:$\mathbb{Z}^{|\mathcal{V}| \times |\mathcal{V}| } \times \mathbb{R}^{|\mathcal{V}| \times m} $ $ \rightarrow \mathbb{R}^{|\mathcal{V}| \times d}$表示任意$k$-layer GNN，它的输出是一个节点嵌入矩阵，并且使用$POOL: \mathbb{R}^{|\mathcal{V}| \times d} \rightarrow \mathbb{R}^d$表示将节点嵌入矩阵$\pmb{Z} \in \mathbb{R}^{|\mathcal{V}| \times d}$映射到图级嵌入向量$\pmb{z}_{\mathcal{G}} \in \mathbb{R}^d$的池函数（如第5章所述）。使用此符号，我们可以通过以下等式定义图形级VAE的编码器：
$$
\mu_{\pmb{z}_{\mathcal{G}}} = POOL_{\mu}(GNN_{\mu}(\pmb{A},\pmb{X})) \quad \log \sigma_{\pmb{z}_{\mathcal{G}}} = POOL_{\sigma}(GNN_{\sigma}(\pmb{A},\pmb{X}))
$$
在这里，我们再次使用两个单独的GNN来参数化潜在变量的后验正态分布的均值和方差。请注意此图形级编码器与上一节中的节点级编码器之间的关键区别，维度不一样，之前是学的点级别的这次是图级别的。因此有:$\pmb{z}_{\mathcal{G}} \sim \mathcal{N}(\mu_{\pmb{z}_{\mathcal{G}}},\sigma_{\pmb{z}_{\mathcal{G}}})$



**Decoder Model**

图级VAE解码模型定义为$p_{\theta}(\mathcal{G}|\pmb{z}_{\mathcal{G}})$，给定图级潜在嵌入的特定图结构的后验分布。最初的GraphVAE模型通过将基本多层感知器（MLP）与伯努利分布假设相结合来解决这一挑战(P133)。在这种方法中，我们使用MLP将潜在向量$\pmb{z}_{\mathcal{G}}$映射到边缘概率矩阵$\pmb{A} \in [0,1]^{|\mathcal{V}| \times |\mathcal{V}|}$
$$
\tilde{A} = \sigma(MLP(\pmb{z}_{\mathcal{G}}))
$$
其中，sigmoid函数$\sigma$用于保证[0,1]中的条目。原则上，我们可以用类似的方式将后验分布定义为节点级情况：
$$
p_{\theta}(\mathcal{G}|\pmb{z}_{\mathcal{G}}) = \prod_{(u,v) \in \mathcal{V}} \pmb{\tilde{A}} [u,v] \pmb{A}[u,v] + (1-\pmb{\tilde{A}}[u,v])(1-\pmb{A}[u,v])
$$
其中$\pmb{A}$表示真实$\mathcal{G}$的邻接矩阵并且$\pmb{\tilde{A}}$ 是我们预测的边概率矩阵。换句话说，我们简单地假设每条边上都有独立的伯努利分布，总体对数似然目标等价于每条边上独立的二元交叉熵损失函数集。然而，在实践中实施等式(12)有两个关键挑战：

1. 首先，如果我们使用MLP作为解码器，那么**我们需要假设固定数量的节点**。通常，通过假设**最大**节点数并使用**掩蔽**方法来解决此问题。特别是，我们可以假设节点的最大数量$n_{max}$，它将解码器MLP的输出维度限制为大小为$n_{max} \times n_{max}$的矩阵。为了在训练期间解码具有$\mathcal{|\mathcal{V}|}<n_{\max}$节点的图，我们只需屏蔽（即忽略）$\pmb{\tilde{A}}$中行或列索引大于$|\mathcal{V}|$的所有条目。为了在模型训练后生成不同大小的图，我们可以指定图大小上的分布$p(n)$，支持$\{2,...,n_{max}\}$，并从该分布中采样以确定生成的图的大小。指定$p(n)$的一个简单策略是使用训练数据中图形大小的经验分布。

2. 在实践中应用等式(12)的第二个关键挑战是，**在计算重建损失时，我们不知道$\pmb{\tilde{A}}$中行和列的正确顺序**。矩阵$\pmb{\tilde{A}}$是由MLP生成的，当我们想用$\pmb{\tilde{A}}$来计算训练图的可能性时，我们需要隐式地假设节点（即$\pmb{\tilde{A}}$的行和列）上的某种顺序。形式上，等式(12)中的损失要求我们指定一个节点排序$\pi \in \Pi$来对$\pmb{\tilde{A}}$中的行和列进行排序。

   这一点很重要，因为如果我们忽略这个问题，then the decoder can overfit to the arbitrary node orderings used during training.。有两种流行的策略来解决这个问题。应用图匹配启发式方法(graph matching heuristic )，试图找到每个训练图中$\pmb{\tilde{A}}$的节点顺序，该顺序给出了最高的可能性，从而修改了
   $$
   p_{\theta}(\mathcal{G}|\pmb{z}_{\mathcal{G}}) = \max_{\pi \in  \Pi} \prod_{(u,v) \in \mathcal{V}} \pmb{\tilde{A}}^\pi [u,v] \pmb{A}[u,v] + (1-\pmb{\tilde{A}}^\pi[u,v])(1-\pmb{A}[u,v])
   $$
   其中我们使用$\pmb{\tilde{A}}^\pi$来表示特定节点序$\pi$下的预测邻接矩阵。然而，不幸的是，计算等式（13）中的最大值——即使使用启发式近似法，计算成本也很高，基于图匹配的模型无法扩展到具有数百个节点的图。最近，作者倾向于使用启发式节点排序。例如，我们可以基于深度优先或广度优先搜索从最高度节点开始排序节点。在这种方法中，我们只需指定一个特定的排序函数$\pi$，并使用该排序计算损失：
   $$
   p_{\theta}(\mathcal{G}|\pmb{z}_{\mathcal{G}}) \approx \prod_{(u,v) \in \mathcal{V}} \pmb{\tilde{A}}^\pi [u,v] \pmb{A}[u,v] + (1-\pmb{\tilde{A}}^\pi [u,v])(1-\pmb{A}[u,v])
   $$
   或者，我们考虑一组小的启发式排序$\pi_1,...,\pi_n$和在这些排序上的平均值：
   $$
   p_{\theta}(\mathcal{G}| \pmb{z}_{\mathcal{G}}) \approx \sum_{\pi_i \in \{\pi_1,...,\pi_n\}} \prod_{(u,v) \in \mathcal{V}} \pmb{\tilde{A}}^{\pi_i} [u,v] \pmb{A}[u,v] + (1-\pmb{\tilde{A}}^{\pi_i}  [u,v])(1-\pmb{A}[u,v])
   $$
   这些启发式排序不能解决图匹配问题，但在实践中似乎效果良好。Liao等人(P115)详细讨论和比较了这些启发式排序方法，并将该策略解释为变分近似(variational approximation)。

**Limitations**

与节点级VAE方法一样，基本图级框架具有严重的局限性。最突出的是，使用图级潜在表示引入了指定节点顺序的问题，如上所述。这个问题加上MLP解码器的使用，目前限制了基本图级VAE在具有数百个或更少节点的小型图中的应用。然而，图级VAE框架可以与更有效的解码器相结合，包括我们在第9.3节中讨论的一些自回归方法，这可以产生更强的模型。当我们强调生成分子图结构的具体任务时，我们将在第9.5节中提到这种方法的一个突出例子。

## 9.2 Adversarial Approaches

变分自动编码器（VAE）是深度生成模型的流行框架，不仅适用于图形，还适用于图像、文本和各种数据域。VAE有一个定义明确的概率动机，并且有许多工作利用和分析VAE模型学习到的潜在空间的结构。然而，VAE也受到严重限制，例如VAE在图像域中产生模糊输出的趋势。许多最新的最先进的生成模型利用了替代的生成框架，其中生成对抗网络（GAN）是最流行的一种(P115)。

基于GAN的生成模型的基本思想如下:

1. 定义一个可训练的生成器网络:$g_\theta:\mathbb{R}^d \rightarrow \mathcal{X}$。通过将随机种子$\pmb{z} \in \mathbb{R}^d$作为输入（例如，来自正态分布的样本），该生成器网络经过训练以生成真实（但虚假）的数据样本$\pmb{\tilde{x}} \in \mathcal{X}$
2. 同时，我们定义了一个鉴别器网络$d_\phi : \mathcal{X} \rightarrow [0,1]$.鉴别器的目标是区分真实数据样本$\pmb{x} \in \mathcal{X}$和生成器$\pmb{\tilde{x}}$生成的样本。这里，我们假设鉴别器输出给定输入为假的概率。

为了训练GAN，在对抗游戏中，发生器和鉴别器都进行了联合优化：
$$
\min_{\theta}\max_{\phi} \mathbb{E}_{\pmb{x} \sim p_{data}(\pmb{x})}[\log(1-d_{\phi}(\pmb{x}))] + \mathbb{E}_{\pmb{z} \sim p_{seed}(\pmb{z})} [\log(d_{\phi}(g_{\theta}(\pmb{z})))]
$$
其中$p_{data}(\pmb{x})$表示真实数据样本的经验分布(例如：从训练集合中均匀抽样)，$p_{seed}(\pmb{z})$表示随机种子分布(例如：一个标准的多元正态分布)。公式(16)表示最小最大优化问题。生成器试图最小化鉴别器的鉴别能力，而鉴别器试图最大限度地提高其检测假样本的能力。GAN minimax目标的优化以及最新的变化具有挑战性，有许多相关的文献(P116)





**A basic GAN approach to graph generation**

在图生成方面，Bojchevski等人[2018]和De Cao和Kipf[2018]首次在并行工作中采用了基于GAN的方法。De Cao和Kipf[2018]提出的基本方法——我们在这里重点讨论的方法与上一节讨论的图形级VAE类似。例如，对于生成器，我们可以使用简单的多层感知器（MLP）来生成给定种子向量$\pmb{z}$的边缘概率矩阵：
$$
\pmb{\tilde{A}}  = \sigma(MLP(\pmb{z}))
$$
给定这个边概率矩阵，我们通过对每条边的独立伯努利变量进行采样，生成一个离散的邻接矩阵$\pmb{\hat{A}} \in \mathbb{Z}^{|\mathcal{V}| \times |\mathcal{V}|}$，它的概率由$\pmb{\tilde{A}}$给出。对于鉴别器，我们可以使用任何基于GNN的图分类模型。然后，可以使用GAN优化的标准工具，根据方程（16）对发生器模型和鉴别器模型进行训练。

**Benefits and limitations of the GAN approach**

与VAE方法一样，图形生成的GAN框架可以以多种方式扩展。可以采用更强大的生成器模型——例如，利用下一节中讨论的自回归技术，甚至可以将节点特征合并到生成器和鉴别器模型中[De Cao和Kipf，2018]。

基于GAN的框架的一个重要优点是，它消除了在损失计算中指定节点顺序的复杂性。只要鉴别器模型是置换不变的（这是几乎所有GNN的情况），那么GAN方法不需要指定任何节点顺序。如果鉴别器是置换不变的，则生成器生成的邻接矩阵的顺序无关紧要。然而，尽管有这一重要优势，基于GAN的图形生成方法迄今为止受到的关注和成功率低于其相应的变分方法。这可能是由于基于GAN的方法所需的最小最大优化所涉及的困难，而研究基于GAN的图形生成的限制目前是一个开放的问题。



## 9.3  Autoregressive Methods

前两节详细介绍了如何将变分自动编码（VAEs）和生成性对抗网络（GANs）的思想应用于图形生成。然而，我们讨论的基于GAN和VAE的基本方法都使用简单的多层感知器（mlp）来生成邻接矩阵。在本节中，我们将介绍更复杂的自回归方法，可以从潜在表示中解码图形结构。我们在本节中介绍的方法可以与我们前面介绍的GAN和VAE框架相结合，但它们也可以作为独立的生成模型进行训练。



### 9.3.1 Model Edge Dependencies

前几节中讨论的简单生成模型假设边是独立生成的。从概率角度出发，我们通过将整体可能性分解为一组独立的边可能性，定义了给定潜在表示$\pmb{z}$的图的可能性，如下所示：
$$
P(\mathcal{G}|\pmb{z}) = \prod_{(u,v) \in \mathcal{V}^2} P(\pmb{A}[u,v]|\pmb{z})
$$
自回归模型放松了边缘独立性的假设。相反，在自回归方法中，我们假设边是按顺序生成的，并且每个边的可能性可以取决于先前生成的边。使用$\pmb{L}$表示邻接矩阵$\pmb{A}$的下三角部分。假定我们处理简单图，$\pmb{A}$与$\pmb{L}$包含了同样的信息，但使用$\pmb{L}$会比较方便。使用$\pmb{L}[v_1,:]$表示对应于节点$v_1$的行，并且我们假定$\pmb{L}$的行indexed by nodes $v_1,...,v_{|\mathcal{V}|}$。这意味着我们只需要关心为任何行$\pmb{L}[v_1,:]$生成前$i$条目；其余的可以简单地用零填充。鉴于此表示法，自回归方法相当于对总体图可能性进行以下分解：
$$
P(\mathcal{G}|\pmb{z}) =\prod_{i=1}^{|\mathcal{V}|} P(\pmb{L}[v_i,:]|\pmb{L}[v_1,:],...,\pmb{L}[v_{i-1},:],\pmb{z})
$$

### 9.3.2 Recurrent Models for Graph Generation

现在我们将讨论自回归生成思想的两个具体实例。在第一个模型中，我们将回顾GraphRNN——我们使用递归神经网络（RNN）对自回归相关性进行建模。在第二种称为图形重复注意网络（GRAN）的方法中，我们通过使用GNN对迄今为止生成的邻接矩阵进行条件化来生成图形。(P118)

**GraphRNN**

采用这种自回归生成方法的第一个模型是GraphRNN(P118)。GraphRNN方法的基本思想是使用分层RNN对方程（19）中的边相关性进行建模。

第一种RNN：称为图级RNN，用于对迄今为止生成的图的状态进行建模。形式上，图级RNN保持隐藏状态$\pmb{h}_i$，该状态在生成邻接矩阵$\pmb{L}[v_i,:]$的每一行后更新：
$$
\pmb{h}_{i+1} = RNN_{graph}(\pmb{h}_i,\pmb{L}[v_i,L])
$$
使用$RNN_{graph}$表示通用RNN状态更新，$h_i$对应于隐藏状态，$\pmb{L}[v_i,L]$对应于观测值。使用固定初始隐藏状态$\pmb{h}_0=\pmb{0}$来初始化图级RNN，但原则上，这种初始隐藏状态也可以通过图形编码器模型来学习，或者以VAE方式从潜在空间采样。

第二种RNN：名为node-level RNN or $RNN_{node}$，以自回归方式生成$\pmb{L}[v_i,:]$的条目。$RNN_{node}$将图形级隐藏状态$\pmb{h}_i$作为初始输入，然后依次生成$\pmb{L}[v_i,:]$的二进制值，假设每个条目都有条件伯努利分布。整个GraphRNN方法称为分层方法，因为节点级RNN在每个时间步都使用图级RNN的当前隐藏状态进行初始化。

使用teaching forcing strategy可以优化图级$RNN_{graph}$和节点级$RNN_{node}$，以最大化训练图（等式19）的可能性，这意味着在训练期间始终使用$\pmb{L}$的基本真值来更新RNN。为了控制生成的图的大小，RNN还被训练为output end-of-sequence tokens，用于指定生成过程的结束。注意，与第9.1节中讨论的图级VAE方法一样，计算等式（19）中的可能性要求我们假设生成节点上的特定顺序。

在训练以最大化训练图的可能性（等式19）之后，GraphRNN模型可用于在测试时通过简单地从固定的初始隐藏状态$\pmb{h}_0$开始运行分层RNN来生成图。由于边级RNN涉及一个随机采样过程来生成离散的边，因此GraphRNN模型能够生成不同的图样本，即使使用固定的初始嵌入。然而，如上所述，GraphRNN模型原则上可以分别用作VAE或GAN框架内的解码器或生成器。

**Graph Recurrent Attention Networks (GRAN)**

上面讨论的GraphRNN方法的主要优点是它可以修改边之间的依赖关系。使用自回归建模假设（等式19），GraphRNN可以根据在生成步骤$1,...,i-1$期间已经生成的图的状态，在生成步骤$i$调节边的生成。通过这种方式进行调节，可以更容易地生成复杂的图案和规则的图形结构，例如网格。例如，在图9.3中，我们可以看到，与基本图级VAE（第9.1节）相比，GraphRNN更能够生成网格状结构。然而，GraphRNN方法仍然存在严重的局限性。如图9.3所示，当在网格样本上进行训练时，GraphRNN模型仍然会生成不现实的伪影（例如，长链）。此外，由于需要通过RNN递归的许多步骤进行反向传播，GraphRNN很难训练并扩展到大型图。

<div align=center>
<img src="/Users/guass/Desktop/markdown/图神经网络/Graph Representation Learning/6png2.png" width="500" height=""/>
</div>

为了解决GraphRN方法的一些局限性，有改进GRAN模型。GRAN表示grpah recurrent attention networks，它保持了生成过程的自回归分解。然而，GRAN没有使用RNN对自回归生成过程建模，而是使用GNN。GRAN中的关键思想是，我们可以通过在迄今为止生成的图上运行GNN来模拟邻接矩阵每一行的条件分布（图9.2）：

<div align=center>
<img src="/Users/guass/Desktop/markdown/图神经网络/Graph Representation Learning/6png1.png" width="500" height=""/>
</div>

$$
P(\pmb{L}[v_i,:]|\pmb{L}[v_1,:],...,\pmb{L}[v_{i-1},:],\pmb{z}) \approx GNN(\pmb{L}[v_1:v_{i-1},:],\pmb{\tilde{X}})
$$

这里$\pmb{L}[v_1:v_{i-1},:]$表示在生成步骤$i$之前生成的图的下三角邻接矩阵。

等式（21）中的GNN可以以多种方式实例化，但关键要求是它生成一个边概率向量$\pmb{L}[v_i,:]$，我们可以从中在生成过程中采样离散边实现。例如，使用图形注意网络（GAT）模型的变体（见第5章）来定义GNN。最后，由于没有与生成的节点相关联的节点属性，GNN的输入特征矩阵$\pmb{\tilde{X}}$可以简单地包含随机采样向量（这有助于区分节点）。

GRAN模型可以通过使用teacher forcing最大化训练图（等式19）的可能性，以与GraphRNN类似的方式进行训练。与GraphRNN模型一样，我们还必须指定节点上的排序，以计算训练图上的可能性，Liao等人(P120)对此挑战进行了详细讨论。最后，与GraphRNN模型一样，我们可以在训练后通过运行随机生成过程（例如，从固定初始状态）将GRAN用作生成模型，但该模型也可以集成到基于VAE或GAN的框架中。

与GraphRNN相比，GRAN模型的关键优势在于，它不需要在图级RNN中维护长期而复杂的历史。相反，GRAN模型在每个生成步骤中使用GNN显式地对已经生成的图施加条件。Liao等人还详细讨论了如何优化GRAN模型，以便于生成具有数十万个节点的大型图。例如，一个关键的性能改进是可以在单个block中同时添加多个节点，而不是一次添加一个节点。这一想法如图9.2所示。



## 9.4 Evaluating Graph Generation

前三节介绍了一系列日益复杂的图形生成方法，这些方法基于VAEs、GANs和自回归模型。在介绍这些方法时，我们暗示了某些方法优于其他方法。我们还在图9.3中提供了一些生成图的示例，这暗示了不同方法的不同功能。然而，我们实际上如何定量地比较这些不同的模型呢？我们怎么能说一种图形生成方法优于另一种？评估生成模型是一项具有挑战性的任务，因为没有准确或错误的自然概念。例如，我们可以比较保留图上的重建损失或模型似然度，**但由于不同生成方法之间缺乏统一的似然定义**，这一点变得复杂。

在一般图生成的情况下，目前的做法是分析生成图的不同统计数据，并将生成图的统计数据分布与测试集进行比较(P120)。形式上，假设我们有一组图统计信息$\mathcal{S} = (s_1,...,s_n)$，其中每个统计信息$s_{i,\mathcal{G}}:\mathbb{R} \rightarrow [0,1]$被假设为定义给定图$\mathcal{G}$的$\mathbb{R}$上的单变量分布。例如，对于给定图$\mathcal{G}$，我们可以计算度分布、聚类系数分布，以及不同motifs或graphlets的分布。给定在测试图$s_{i,\mathcal{G}_{test}}$和生成图$s_{i,\mathcal{G}_{gen}}$上计算的特定统计$s_i$，我们可以使用分布测度计算测试图和生成图上的统计分布之间的距离，例如总变化距离：
$$
d(s_{i,\mathcal{G}_{test}},s_{i,\mathcal{G}_{gen}}) = \sup_{x \in \mathbb{R}} |s_{i,\mathcal{G}_{test}}(x) -s_{i,\mathcal{G}_{gen}}(x)|
$$
为了获得性能度量，我们可以计算生成的一组图和测试集中的图之间的平均成对分布距离。

现有研究已将该策略用于度分布、图计数和光谱特征等图形统计，并使用总变异分数和第一Wasserstein距离的变量计算分布距离(P121)



## 9.5 Molecule Generation

到目前为止，我们介绍的所有图生成方法都适用于一般的图生成。前面的部分没有假设特定的数据域，我们的目标只是基于给定的图形训练集生成真实的图形结构（即邻接矩阵）。然而，值得注意的是，在图形生成的一般领域中，许多工作都专门关注分子生成的任务。

分子生成的目标是生成既有效（例如，化学稳定性）又理想地具有某些理想性质（例如，药物性质或溶解度）的分子图结构。与一般的图形生成问题不同，分子生成的研究可以从模型设计和评估策略的特定领域知识中获益匪浅。例如，Jin等人[2018]提出了图形级VAE方法的高级变体（第9.1节），该方法利用了关于已知分子基序的知识。鉴于对特定领域知识的强烈依赖以及与一般图相比分子生成的独特挑战，我们在此不详细回顾这些方法。尽管如此，重要的是要强调该领域是图形生成中增长最快的子领域之一。









# 10. Conclusion



近年来，图形表示学习已正式成为机器学习社区中一个真正的、可识别的子领域。由于对这一主题的研究越来越重视，图形神经网络（GNNs）现在已经成为一种相对标准的技术；现在有几十种图形的深层生成模型；而且，我们对这些技术的理论理解正在迅速固化。然而，这种固化也带来了停滞的风险，因为某些方法变得根深蒂固，研究的重点变得越来越狭窄。

**Latent graph inference**

总的来说，本书中介绍的技术假设一个图形结构作为输入。正如我所介绍的，图形表示学习的挑战在于如何以有效的方式嵌入或表示这样一个给定的输入图形。然而，一个同样重要且互补的挑战是从非结构化或（半结构化）输入推断图形或关系结构。这个任务有很多名字，但我在这里称之为潜在图推理。潜在图推理是图表示学习的一个基本挑战，主要是因为它允许我们在没有输入图的情况下使用类似GNN的方法。从技术角度来看，这一研究方向可能以本书第三部分介绍的图形生成工具为基础。 

在这一领域已经有了有希望的初步工作，如Kipf等人[2018]提出的神经关系推理（NRI）模型和Wang等人[2019]推断的最近邻图。也许这个研究方向最令人兴奋的事实是，初步发现表明，即使我们有一个输入图，潜在图推理也可能提高模型性能。**在我看来，构建能够推断出给定输入图之外的潜在图结构的模型是推进图表示学习的一个关键方向，这也可以打开无数新的应用领域。**

**Breaking the bottleneck of message passing**

就空间而言，本书中最大的一个主题可能是神经信息传递方法，首次在第5章中介绍。这种消息传递形式主义，即节点聚合来自邻居的消息，然后以迭代方式更新其表示，是当前GNN的核心，并已成为图形表示学习的主导范式。

然而，神经信息传递范式也有严重的缺陷。正如我们在第7章中所讨论的，消息传递GNN的能力本质上受到Weisfeiler-Lehman（WL）同构测试的限制。此外，我们知道这些消息传递GNN在理论上与相对简单的卷积滤波器有关，卷积滤波器可以由（规范化）邻接矩阵的多项式形成。根据经验，研究人员不断发现消息传递GNN存在过度平滑问题，这种过度平滑问题可以看作是当前GNN核心的邻域聚合操作的结果。事实上，在其核心，消息传递GNN本质上受到聚合和更新消息传递范式的限制。这种范式诱导了WL同构测试以及简单图卷积的理论联系，但它也基于这些理论构造诱导了这些GNN的功率边界。在更直观的层面上，我们可以看到，GNNs的聚合和更新消息传递结构本质上导致了树结构计算（如图5.1所示）。每个节点在GNN中的嵌入依赖于邻域信息的迭代聚合，邻域信息可以表示为植根于该节点的树结构计算图。注意到GNN仅限于树结构计算图，这提供了对其局限性的另一种看法，例如它们无法一致地识别周期，并且无法捕获图中节点之间的长期依赖关系。

我认为，消息传递GNNs的核心局限性——即受WL测试的限制，局限于简单的卷积滤波器，以及局限于树结构计算图——实际上都是一个共同的根本原因的不同方面。为了推进图形表示学习，有必要理解这些理论观点之间更深层次的联系，我们需要找到能够打破这些理论瓶颈的新架构和范例。









<center> <font size=6 ><b>卷积滤波器、WL测试</b></font></center> 













